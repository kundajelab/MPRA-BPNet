"""Train MPRA models
inputs have to be one-hot encoded using create_one_hot_seq.py before running this script to ensure that the random sequences added to the input during theprocess is preserved for all downstream analyses
"""
from config import model_exps
import pandas as pd
import numpy as np
from basepair.exp.paper import activity
from basepair.exp.paper.activity import load_data, train_activity_model
from basepair.config import create_tf_session
from basepair.seqmodel import SeqModel
from basepair.utils import (kwargs_str2kwargs, flatten,
                            read_pkl, read_json, write_pkl)
from gin_train.utils import write_json
from pathlib import Path
from keras.models import Sequential
from keras.layers import Dense, Activation
from keras import initializers  
from keras.optimizers import Adam
from tensorflow import set_random_seed
from keras.wrappers.scikit_learn import KerasRegressor
from sklearn.model_selection import cross_val_predict
from util_cross_val import *
set_random_seed(1234)
from matplotlib import pyplot


GPU = 3
experiments = list(model_exps.values())  # [:1]

# --------------------------------------------
rule all:
    input:
        'output_0604_top_layer/cv_free_MPRA.csv',
        metrics_dict = expand('output_0604_top_layer/{exp}/MPRA/{dataset}/{data_hparams}/{model}/LinearRegressor.metrics.json',
                              dataset=['synthetic', 'genomic'],
                              data_hparams=['pool_size=15'],
                              model=[
                                  'LinearRegressor'
                              ],
                              exp=experiments),

# --------------------------------------------


rule train:
    input:
        input_gen = '../tidied_GEN_RPMsExpression_plusSeqs',
        input_syn = '../tidied_SYN_RPMsExpression_plusSeqs',
    output:
        preds = 'output_0604_top_layer/{exp}/MPRA/{dataset}/{data_hparams}/{model}/LinearRegressor.preds.pkl',
        output_kwargs = 'output_0604_top_layer/{exp}/MPRA/{dataset}/{data_hparams}/{model}/kwargs.json',
        bottleneck_models = 'output_0604_top_layer/{exp}/MPRA/{dataset}/{data_hparams}/{model}/bottleneck_model.h5',
	top_layers = 'output_0604_top_layer/{exp}/MPRA/{dataset}/{data_hparams}/{model}/top_layer.h5',
    params:
        n_folds = 5
    threads: 5
    run:
        from basepair.exp.chipnexus.data import(pool_bottleneck,
                                                 gen_padded_sequence,
                                                 syn_padded_sequence,
                                                 )
        
        from concise.preprocessing import encodeDNA
        from concise.preprocessing.sequence import one_hot2string, DNA

        model_name = wildcards.model
        data_kwargs = kwargs_str2kwargs(wildcards.data_hparams)
	dfs_gen = pd.read_csv(input.input_gen)
	dfs_syn = pd.read_csv(input.input_syn)
        if wildcards.dataset == 'genomic':
            dfs = dfs_gen
            bpnet_seq = np.load("tidied_GEN_RPMsExpression_plusSeqs_one_hot.npy")
            #bpnet_seq = encodeDNA([gen_padded_sequence(s, "AAAGACGCG")
                                   #for s in dfs.Sequence.str.upper()])
        elif wildcards.dataset == 'synthetic':
            dfs = dfs_syn
            bpnet_seq = np.load("tidied_SYN_RPMsExpression_plusSeqs_one_hot.npy")
            #bpnet_seq = encodeDNA([syn_padded_sequence(s, "AAAGACGCG")
                                   #for s in dfs.Sequence.str.upper()])
        else:
            raise ValueError("dataset not genomic or synthetic")
        y_true = dfs.expression_fc_log2.values

        # Get bottleneck predictions
	models_dir = Path('/oak/stanford/groups/akundaje/avsec/basepair/data/processed/comparison/output/')
        mdir = models_dir / wildcards.exp
        create_tf_session(GPU)
        bottleneck_model = SeqModel.from_mdir(mdir).bottleneck_model()
        bpnet_bottleneck = bottleneck_model.predict(bpnet_seq)
        bpnet_bottleneck_feat = pool_bottleneck(bpnet_bottleneck, outlen=80, agg_fn=np.max, **data_kwargs)
        #only used when tuning the hyperparameters
	#neural_network = KerasRegressor(create_top_model_fn(y_true),epochs = 2500, batch_size = 256)
	#y_pred = cross_val_predict(neural_network,bpnet_bottleneck_feat, y_true,cv = params.n_folds,n_jobs=threads,fit_params = {'callbacks': [EarlyStopping(monitor = "loss",mode = "min", patience = 30,min_delta = 0.0001,restore_best_weights = True)]})
	
	#retrain the model:
        real_layer = create_top_model(y_true)
        real_layer.fit(bpnet_bottleneck_feat, y_true, epochs = 2500, batch_size = 256)
	y_pred = real_layer.predict(bpnet_bottleneck_feat)
	bottleneck_model.save(output.bottleneck_models)
	real_layer.save(output.top_layers)
	write_json(
            {
                "exp": wildcards.exp,
                "data": wildcards.dataset,
                "data_kwargs": data_kwargs,
                "model": model_name,
            }, output.output_kwargs)

        # Note: keep the output 2 dimensional
        write_pkl({"y_true": y_true[:, np.newaxis],
                   "y_pred": y_pred[:, np.newaxis],
                   "columns": [wildcards.dataset]}, output.preds)

rule evaluate:
    """Evaluate the regression models
    """
    input:
        preds = 'output_0604_top_layer/{exp}/MPRA/{dataset}/{data_hparams}/{model}/LinearRegressor.preds.pkl',
    output:
        metrics = 'output_0604_top_layer/{exp}/MPRA/{dataset}/{data_hparams}/{model}/LinearRegressor.metrics.json',
    run:
        preds = read_pkl(input.preds)
        from gin_train.metrics import RegressionMetrics
        m = RegressionMetrics()
        # out = {"split": wildcards.split, "metrics": dict()}
        out = {"split": 'regressor', "metrics": dict()}
        for i, c in enumerate(preds['columns']):
            out['metrics'][c] = m(preds['y_true'][:, i],
                                  preds['y_pred'][:, i])
        write_json(out, output.metrics)


rule gather:
    input:
        metrics_dict = expand('output_0604_top_layer/{exp}/MPRA/{dataset}/{data_hparams}/{model}/LinearRegressor.metrics.json',
                              dataset=['synthetic', 'genomic'],
                              data_hparams=['pool_size=15'],
                              model=[
                                  'LinearRegressor'
                              ],
                              exp=experiments),
    output:
        table = 'output_0604_top_layer/cv_free_MPRA.csv'
    run:
        import pandas as pd
        outl = []
        for json in input.metrics_dict:
            metrics = read_json(json)
            kwargs = read_json(os.path.join(os.path.dirname(json), 'kwargs.json'))
            out = flatten({**metrics, **kwargs}, "/")
            outl.append(out)
        # write the results to csv
        pd.DataFrame(outl).to_csv(output.table, index=False)
